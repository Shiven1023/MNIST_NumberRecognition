{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "834731f1-be82-4d91-af4a-57cfdef47d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder \n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e766347-5f04-4348-be16-3aa430d31cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Load Training Data ----------\n",
    "train_path = \"/Users/raaghav/Downloads/mnist_png/training\"\n",
    "train_data, train_labels = [], []\n",
    "\n",
    "for label in os.listdir(train_path):\n",
    "    folder = os.path.join(train_path, label)\n",
    "    if not os.path.isdir(folder):   # ✅ skip .DS_Store or files\n",
    "        continue\n",
    "    for file in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, file)\n",
    "        img = Image.open(img_path).convert(\"L\")  \n",
    "        arr = np.array(img).flatten()   # 784 values\n",
    "        train_data.append(arr)\n",
    "        train_labels.append(int(label))\n",
    "\n",
    "# ---------- Load Testing Data ----------\n",
    "test_path = \"/Users/raaghav/Downloads/mnist_png/testing\"\n",
    "test_data, test_labels = [], []\n",
    "\n",
    "for label in os.listdir(test_path):\n",
    "    folder = os.path.join(test_path, label)\n",
    "    if not os.path.isdir(folder):   # ✅ skip .DS_Store or files\n",
    "        continue\n",
    "    for file in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, file)\n",
    "        img = Image.open(img_path).convert(\"L\")  \n",
    "        arr = np.array(img).flatten()  \n",
    "        test_data.append(arr)\n",
    "        test_labels.append(int(label))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68e41fb9-b1b5-4254-a478-496748f2d639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "train_data = np.array(train_data) / 255.0   # normalize\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "test_data = np.array(test_data) / 255.0\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4044a88-dec7-4a31-8570-9209e77b28e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Convert to PyTorch tensors\n",
    "X_train = torch.tensor(train_data, dtype=torch.float32)\n",
    "y_train = torch.tensor(train_labels, dtype=torch.long)\n",
    "\n",
    "X_test = torch.tensor(test_data, dtype=torch.float32)\n",
    "y_test = torch.tensor(test_labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0312fde0-37e5-4cc0-9bf5-625ae4e86004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Datasets and Loaders \n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)#loads the training and testing data in small batches\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b14cf87-f143-4513-bb02-6a1187c681e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a7f799e-2b01-4ced-86dd-3737cf1e77e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "\n",
    "        # Layer 1(hidden): 128 neurons\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "\n",
    "        # Layer 2(hidden): 64 neurons\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "\n",
    "        # Output layer: 10 neurons for 0-9 outputs\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ReLU activation for Layer1\n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "        # ReLU activation for Layer2\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        # Pass through final output layer (no activation, CrossEntropyLoss(our loss function) will apply Softmax)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f43d533-1aec-46ea-8e54-bef3ead52075",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet()  \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) #choosing loss function , optimizer and learning rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e0dedd1-a4fa-4dc8-b5db-c0de759d7c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.3478\n",
      "Epoch 2/5, Loss: 0.1442\n",
      "Epoch 3/5, Loss: 0.0987\n",
      "Epoch 4/5, Loss: 0.0759\n",
      "Epoch 5/5, Loss: 0.0591\n"
     ]
    }
   ],
   "source": [
    "epochs = 5  \n",
    "for epoch in range(epochs):\n",
    "    model.train()  \n",
    "    running_loss = 0.0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7cd0b04-c3a5-4603-b60a-8a596a5ef11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.39%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # set to evaluation mode\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.no_grad():  \n",
    "    for X_batch, y_batch in test_loader:\n",
    "        outputs = model(X_batch)\n",
    "        _, predicted = torch.max(outputs, 1)  # highest logit = prediction\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a410012-053c-414a-9187-32b6e74fdfe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
